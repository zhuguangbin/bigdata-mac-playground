## Hive

1. 下载Hive安装包

我们选择hive的2.3.6版本部署。（实际上hive目前有三个大版本，1.x，2.x，3.x。1.x不建议玩了，3.x比较新，有比较大的改动，2.x是普适性最好的）

```
sudo wget -P /opt https://archive.apache.org/dist/hive/hive-2.3.6/apache-hive-2.3.6-bin.tar.gz
cd /opt
sudo tar zxvf apache-hive-2.3.6-bin.tar.gz 
sudo ln -nsf apache-hive-2.3.6-bin hive
```

执行完以上后，我们还需要一步，就是将mysql的jdbc driver的jar安装到hive的lib下。

```
sudo wget -P /opt/hive/lib/ https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.38/mysql-connector-java-5.1.38.jar
```

2. 部署mysql作为hive metastore的后端存储

我们用docker来部署一个mysqlserver，借助docker的隔离，不用折腾一堆系统环境的依赖了。

a. 首先你得先启动docker

在第一节Mac基础环境配置中，我们已经安装过Mac的docker desktop了。在Launchpad中找到Docker应用的图标，点击启动即可。

b. 安装mysqlserver

我封装了一个脚本，用来按照部署mysqlserver，放到[scripts/install-mysqlserver](../../scripts/install-mysqlserver/)下了。

其中`mysql-env.sh`是我们要安装的mysqlserver的基本配置，包括主机名、端口、root用户名密码、初始化db等。你可以保持默认，当然你也可以根据你实际情况修改。

执行以下脚本即可一键安装：
```
sudo sh start-mysqlserver-docker.sh
```

当看到`====数据库安装配置完毕, enjoy======`提示时，即代表安装完成。 执行`docker ps`来检查下:
```
$ docker ps
CONTAINER ID   IMAGE     COMMAND                  CREATED       STATUS          PORTS                               NAMES
1a295b35de18   mysql:5   "docker-entrypoint.s…"   11 days ago   Up 11 seconds   0.0.0.0:3306->3306/tcp, 33060/tcp   mysqlserver

```

c. 安装mysql客户端

我们用HomeBrew来安装一个mysql客户端，当然你也可以用一些MySQL客户端的App，比如Navicat等等。我们还是用命令行更轻量级。

```
brew install mysql-client
```

安装完毕后，mysql客户端相关的命令就安装到了`/usr/local/opt/mysql-client/bin`下，熟悉不？
```
$ ls -l /usr/local/opt/mysql-client/bin 
total 254080
-r-xr-xr-x  1 guangzhu  admin  6522376 May 10 22:47 comp_err
-r-xr-xr-x  1 guangzhu  admin  6590536 May 10 22:47 lz4_decompress
-r-xr-xr-x  1 guangzhu  admin  6503664 May 10 22:47 my_print_defaults
-r-xr-xr-x  1 guangzhu  admin  6874080 May 10 22:47 mysql
-r-xr-xr-x  1 guangzhu  admin     5195 May 10 22:47 mysql_config
-r-xr-xr-x  1 guangzhu  admin  6523744 May 10 22:47 mysql_config_editor
-r-xr-xr-x  1 guangzhu  admin  6879256 May 10 22:47 mysql_migrate_keyring
-r-xr-xr-x  1 guangzhu  admin  6749208 May 10 22:47 mysql_secure_installation
-r-xr-xr-x  1 guangzhu  admin  6549328 May 10 22:47 mysql_ssl_rsa_setup
-r-xr-xr-x  1 guangzhu  admin  6770200 May 10 22:47 mysqladmin
-r-xr-xr-x  1 guangzhu  admin  7176752 May 10 22:47 mysqlbinlog
-r-xr-xr-x  1 guangzhu  admin  6772000 May 10 22:47 mysqlcheck
-r-xr-xr-x  1 guangzhu  admin  6829136 May 10 22:47 mysqldump
-r-xr-xr-x  1 guangzhu  admin  6756584 May 10 22:47 mysqlimport
-r-xr-xr-x  1 guangzhu  admin  7502624 May 10 22:47 mysqlpump
-r-xr-xr-x  1 guangzhu  admin  6752544 May 10 22:47 mysqlshow
-r-xr-xr-x  1 guangzhu  admin  6776016 May 10 22:47 mysqlslap
-r-xr-xr-x  1 guangzhu  admin  7782568 May 10 22:47 mysqltest
-r-xr-xr-x  1 guangzhu  admin  7279880 May 10 22:47 perror
-r-xr-xr-x  1 guangzhu  admin  6450880 May 10 22:47 zlib_decompress

```

把mysql相关的命令加入PATH，以方便使用。

```
echo 'export PATH="/usr/local/opt/mysql-client/bin:$PATH"' >> ~/.zshrc

source ~/.zshrc
```

d. 初始化hive metastore的`hive2_meta`库

`hive2_meta`是我们在安装mysqlserver时在`mysql-env.sh`中指定的DB作为hive metastore的后端存储DB。

```
$ mysql -h 127.0.0.1 -P3306 -u root -p hive2_meta < /opt/hive/scripts/metastore/upgrade/mysql/hive-schema-2.3.0.mysql.sql 
Enter password: 
```

初始化好后，可以登录mysql看一下：

```
$ mysql -h 127.0.0.1 -P3306 -u root -p hive2_meta
Enter password: 
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 3
Server version: 5.7.38 MySQL Community Server (GPL)

Copyright (c) 2000, 2022, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show tables;
+---------------------------+
| Tables_in_hive2_meta      |
+---------------------------+
| AUX_TABLE                 |
| BUCKETING_COLS            |
| CDS                       |
| COLUMNS_V2                |
| COMPACTION_QUEUE          |
| COMPLETED_COMPACTIONS     |
| COMPLETED_TXN_COMPONENTS  |
| DATABASE_PARAMS           |
| DBS                       |
| DB_PRIVS                  |
| DELEGATION_TOKENS         |
| FUNCS                     |
| FUNC_RU                   |
| GLOBAL_PRIVS              |

......
```

可以看到已经初始化好所有的表


3. 配置Hive的配置文件

如上节配置hadoop一样，我把我的配置文件放到[conf/hive](../../conf/hive/) 下，供你直接可用

```
sudo mkdir /etc/hive
cd /etc/hive
sudo ln -nsf ~/Code/github/zhuguangbin/bigdata-mac-playground/conf/hive/conf.local conf
```

4. 环境变量

 将以下环境变量加入`~/.zshrc`

```
export HIVE_HOME=/opt/hive
export HIVE_CONF_DIR=/etc/hive/conf
export PATH=$HIVE_HOME/bin:$PATH
```

`source ~/.zshrc`生效

5. 启动hive metastore server

Hive 依赖HDFS，所以，启动metastore server前，先启动HDFS。（如上节内容所述）

```
cd /opt/hadoop
sbin/start-dfs.sh
```

启动hive metastore server：

```
cd /opt/hive
bin/hive --service metastore &
```

```
$ jps
21728 SecondaryNameNode
34929 RunJar
35154 Jps
21515 NameNode
21613 DataNode
```

这个`RunJar`进程就是hive metastore了。

6. 初体验

我们先启动YARN，体验下Hive on MR。

```
cd /opt/hadoop
sbin/start-yarn.sh
```

进入Hive CLI：
```
$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/apache-hive-2.3.6-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.5/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/opt/apache-hive-2.3.6-bin/lib/hive-common-2.3.6.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> show databases;
OK
default
Time taken: 0.755 seconds, Fetched: 1 row(s)
hive> create database test;
OK
Time taken: 1.226 seconds
hive> use test;
OK
Time taken: 0.051 seconds
hive> CREATE TABLE `hello_hive`(
    >   `id` bigint, 
    >   `name` string)
    > STORED AS ORC;
OK
Time taken: 0.138 seconds
hive> show tables;
OK
hello_hive
Time taken: 0.037 seconds, Fetched: 1 row(s)
hive> insert into hello_hive values(1,"Bob"),(2,"Alice"),(3,"Lucy");
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = guangzhu_20220510231941_712a6d49-3c17-43ec-9bd4-5c135c2cbd79
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1652196000205_0001, Tracking URL = http://localhost:8088/proxy/application_1652196000205_0001/
Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1652196000205_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2022-05-10 23:20:30,266 Stage-1 map = 0%,  reduce = 0%
2022-05-10 23:20:35,446 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_1652196000205_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://localhost:8020/user/hive/warehouse/test.db/hello_hive/.hive-staging_hive_2022-05-10_23-19-41_259_1656570059175163025-1/-ext-10000
Loading data to table test.hello_hive
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   HDFS Read: 4467 HDFS Write: 384 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 56.036 seconds
hive> select * from hello_hive;
OK
1	Bob
2	Alice
3	Lucy
Time taken: 0.113 seconds, Fetched: 3 row(s)

```

至此，hive已经部署完毕。

我们其实主要依赖的是Hive metastore server（HMS），而计算引擎上，大多数公司已经倾向于从MR迁移到Spark，也就是利用HMS做元数据管理，而ETL计算采用SparkSQL。下一节，我们将介绍Spark的安装。

