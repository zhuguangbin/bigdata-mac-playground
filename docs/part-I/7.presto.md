## Presto

Presto是由Facebook开源的一个 MPP计算引擎，主要用来以解决Facebook海量Hadoop数据仓库的低延迟交互分析问题，Facebook版本的Presto更多的是以解决企业内部需求功能为主，也叫PrestoDB，版本号以0.xxx来划分。后来，Presto其中的几个人出来创建了更通用的Presto分支，取名Presto SQL，版本号以 xxx 来划分，例如 345 版本，这个开源版本也是更为被大家通用的版本。前一段时间，为了更好地与 Facebook 的 Presto 进行区分，Presto SQL 将名字改为 Trino，除了名字改变了其他都没变。不管是 Presto DB 还是 Presto SQL，它们"本是同根生"，因此它们的大部分的机制原理是一样的。

Presto是一个纯粹的计算引擎，它不存储数据，其通过Connector获取第三方Storage服务的数据。由于其云原生和多connector的架构，使其很流行的作为湖仓分析的OLAP引擎。

这篇我们介绍Presto的安装部署，我们选择prestodb版本，当然你也可以选择trino，不过trino的最新版本依赖最低JDK11的版本，所以，在使用trino前先用HomeBrew部署一个高版本的JDK。本篇我们选择prestodb的最新版本，JDK8仍然可用。

1. 下载Presto安装包

```
sudo wget -P /opt https://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.273.1/presto-server-0.273.1.tar.gz
cd /opt
sudo tar zxvf presto-server-0.273.1.tar.gz
sudo ln -nsf presto-server-0.273.1 presto

## presto cli
sudo wget -P /opt/presto/bin https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.273.1/presto-cli-0.273.1-executable.jar
sudo mv /opt/presto/bin/presto-cli-0.273.1-executable.jar /opt/presto/bin/presto
sudo chmod a+x /opt/presto/bin/presto
```

2. 配置Presto

我们将presto的运行时数据统一放在/data/presto下
```
mkdir /data/presto
```

presto的配置统一放到/etc/presto下，配置文件我已经整理好放到[conf/presto](../../conf/presto/)了，你可以拿到直接使用。
```
sudo mkdir /etc/presto
sudo ln -nsf ~/Code/github/zhuguangbin/bigdata-mac-playground/conf/presto/conf.local conf
```

3. 环境变量

我们将以下环境变量加入 ~/.zshrc

```
export PRESTO_HOME=/opt/presto
export PATH=$PATH:$PRESTO_HOME/bin
```
source ~/.zshrc 生效

4. 启动Presto

使用以下命令启动presto server
```
$bin/launcher run --etc-dir=/etc/presto/conf --data-dir=/data/presto
```

这个命令将PrestoServer前台启动，如果要后台启动，可以执行以下命令:
```
$ bin/launcher start --etc-dir=/etc/presto/conf --data-dir=/data/presto
Started as 99103
$tail -f  /data/presto/var/log/server.log
```

你可以在浏览器输入`http://localhost:8080/` 访问Presto的WebUI。

5. Presto初体验

安装配置好后，我们直接执行`presto`命令，进入presto的cli命令行客户端。以下是一个最基本的demo：

```
$ presto
presto> show catalogs;
   Catalog   
-------------
 local_hive1 
 local_hive2 
 system      
(3 rows)

Query 20220522_142757_00000_5svv4, FINISHED, 1 node
Splits: 19 total, 19 done (100.00%)
0:01 [0 rows, 0B] [0 rows/s, 0B/s]

presto> show schemas from local_hive2;
       Schema       
--------------------
 default            
 flink_rt_db        
 flink_sql_cookbook 
 hive_db            
 hudi_db            
 iceberg_db         
 information_schema 
 test               
(8 rows)

Query 20220522_142806_00001_5svv4, FINISHED, 1 node
Splits: 19 total, 19 done (100.00%)
337ms [8 rows, 122B] [23 rows/s, 362B/s]

presto> show schemas from local_hive1;
       Schema       
--------------------
 default            
 information_schema 
 test1              
(3 rows)

Query 20220522_142815_00002_5svv4, FINISHED, 1 node
Splits: 19 total, 19 done (100.00%)
136ms [3 rows, 45B] [22 rows/s, 331B/s]

presto> use local_hive2.test;
USE
presto:test> show tables;
       Table       
-------------------
 hello_hive        
 hello_hive2_table 
 hello_spark       
(3 rows)

Query 20220522_142828_00004_5svv4, FINISHED, 1 node
Splits: 19 total, 19 done (100.00%)
399ms [3 rows, 80B] [7 rows/s, 200B/s]

presto:test> select * from hello_hive;
 id | name  
----+-------
  1 | Bob   
  2 | Alice 
  3 | Lucy  
(3 rows)

Query 20220522_142836_00005_5svv4, FINISHED, 1 node
Splits: 17 total, 17 done (100.00%)
0:01 [3 rows, 312B] [2 rows/s, 296B/s]

presto:test> use local_hive1.test1;
USE
presto:test1> show tables;
       Table       
-------------------
 hello_hive1_table 
(1 row)

Query 20220522_142849_00009_5svv4, FINISHED, 1 node
Splits: 19 total, 19 done (100.00%)
202ms [1 rows, 32B] [4 rows/s, 158B/s]

presto:test1> select * from hello_hive1_table;
 id | name  
----+-------
  1 | Bob   
  2 | Alice 
  3 | Lucy  
(3 rows)

Query 20220522_142859_00010_5svv4, FINISHED, 1 node
Splits: 17 total, 17 done (100.00%)
265ms [3 rows, 21B] [11 rows/s, 79B/s]

presto:test1> select * from (select * from local_hive1.test1.hello_hive1_table union all select * from local_hive2.test.hello_hive);
 id | name  
----+-------
  1 | Bob   
  2 | Alice 
  3 | Lucy  
  1 | Bob   
  2 | Alice 
  3 | Lucy  
(6 rows)

Query 20220522_142938_00011_5svv4, FINISHED, 1 node
Splits: 18 total, 18 done (100.00%)
276ms [6 rows, 333B] [21 rows/s, 1.18KB/s]

presto:test1> describe hello_hive1_table;
 Column |  Type   | Extra | Comment 
--------+---------+-------+---------
 id     | bigint  |       |         
 name   | varchar |       |         
(2 rows)

Query 20220522_143010_00013_5svv4, FINISHED, 1 node
Splits: 19 total, 19 done (100.00%)
189ms [2 rows, 141B] [10 rows/s, 746B/s]

presto:test1> help

Supported commands:
QUIT
EXPLAIN [ ( option [, ...] ) ] <query>
    options: FORMAT { TEXT | GRAPHVIZ }
             TYPE { LOGICAL | DISTRIBUTED }
DESCRIBE <table>
SHOW COLUMNS FROM <table>
SHOW FUNCTIONS
SHOW CATALOGS [LIKE <pattern>]
SHOW SCHEMAS [FROM <catalog>] [LIKE <pattern>]
SHOW TABLES [FROM <schema>] [LIKE <pattern>]
USE [<catalog>.]<schema>

presto:test1> 
```

如上所示，我们配置了两个hive的catalog，一个local_hive2是hive 2.3.6的数据源，一个local_hive1是hive 1.2.1的数据源。可以看到presto天然支持CATALOG语义，可以将两个数据源做联邦查询。谈到这里，是不是比[Spark支持多Hive数据源](../part-II/1.spark-multi-catalog.md)的方案简单很多了。
Presto支持的connector非常丰富，而开发拓展自己的connector也很简单，可以轻松对接很多数据源，实现任意多数据源的联邦查询，比如hive事实表 join mysql维表，而无需将数据导入，我想这也是presto很流行的一大重要原因。

本节只是简单的介绍了Presto的最基础使用，到此，我们部署完毕了最基础的大数据的组件。从数据引擎这个角度，Spark作为离线ETL计算引擎，Flink作为实时流处理引擎，Presto作为OLAP交互式分析引擎。

接下来，我们会介绍利用这些引擎与Hive数仓与Hudi/Iceberg数据湖方案，来构建流批一体湖仓（Lakehouse）的整体方案。