## Kafka

1. 下载Kafka安装包

我们选择Kafka 2.4.1版本，实际上现在Kafka最新版本3.2.0（写稿时刚刚发布）。为什么选择2.4.1，因为flink默认跟kafka的集成是2.4.1版本，实际上flink对kafka版本没有要求，理论上是都支持的。如果你想体验kafka新版本的功能，可以选择最新版本。

```
sudo wget -P /opt https://archive.apache.org/dist/kafka/2.4.1/kafka_2.11-2.4.1.tgz
cd /opt
sudo tar zxvf kafka_2.11-2.4.1.tgz
sudo ln -nsf kafka_2.11-2.4.1 kafka
```

2. 配置Kafka的配置文件

我把我的配置文件放到[conf/kafka](../../conf/kafka/) 下，供你直接可用。

```
sudo mkdir /etc/kafka
cd /etc/kafka
sudo ln -nsf ~/Code/github/zhuguangbin/bigdata-mac-playground/conf/kafka/conf.local conf
```

3. 启动Kafka集群

这里有一个对目录的前提要求，`/data/zookeeper`和`/data/kafka` 要提前创建好，我们在第一节Mac基础环境的时候已经配置好，继续。

先启动zookeeper
```
$ bin/zookeeper-server-start.sh 
USAGE: bin/zookeeper-server-start.sh [-daemon] zookeeper.properties

$ bin/zookeeper-server-start.sh -daemon /etc/kafka/conf/zookeeper.properties 
```

再启动kafka broker
```
$ bin/kafka-server-start.sh 
USAGE: bin/kafka-server-start.sh [-daemon] server.properties [--override property=value]*

$ bin/kafka-server-start.sh -daemon /etc/kafka/conf/server.properties 
```

可以通过以下方式来分别查看zookeeper和broker的日志，如果没有异常则启动成功了。
```
tail -f logs/zookeeper.out
tail -f logs/server.log
```

4. Kafka初体验

创建一个topic `hello-kafka`

```
$ bin/kafka-topics.sh --bootstrap-server localhost:9092 -create --topic hello-kafka

$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
hello-kafka
```

让我们造一些测试数据，顺便来测试下kafka的性能：
```
$ bin/kafka-producer-perf-test.sh --topic hello-kafka --num-records 1000000 --throughput -1 --producer.config /etc/kafka/conf/producer.properties --record-size 10240 --print-metrics
26550 records sent, 5310.0 records/sec (51.86 MB/sec), 357.3 ms avg latency, 704.0 ms max latency.
48751 records sent, 9750.2 records/sec (95.22 MB/sec), 210.9 ms avg latency, 243.0 ms max latency.
51990 records sent, 10398.0 records/sec (101.54 MB/sec), 197.0 ms avg latency, 269.0 ms max latency.
53082 records sent, 10616.4 records/sec (103.68 MB/sec), 193.1 ms avg latency, 248.0 ms max latency.
55105 records sent, 11021.0 records/sec (107.63 MB/sec), 186.0 ms avg latency, 212.0 ms max latency.
55525 records sent, 11105.0 records/sec (108.45 MB/sec), 183.9 ms avg latency, 206.0 ms max latency.
54772 records sent, 10954.4 records/sec (106.98 MB/sec), 187.6 ms avg latency, 279.0 ms max latency.
56000 records sent, 11200.0 records/sec (109.38 MB/sec), 183.0 ms avg latency, 210.0 ms max latency.
51875 records sent, 10375.0 records/sec (101.32 MB/sec), 196.9 ms avg latency, 292.0 ms max latency.
53564 records sent, 10712.8 records/sec (104.62 MB/sec), 191.6 ms avg latency, 270.0 ms max latency.
52683 records sent, 10536.6 records/sec (102.90 MB/sec), 194.4 ms avg latency, 282.0 ms max latency.
52329 records sent, 10465.8 records/sec (102.21 MB/sec), 195.7 ms avg latency, 276.0 ms max latency.
51337 records sent, 10267.4 records/sec (100.27 MB/sec), 199.3 ms avg latency, 276.0 ms max latency.
55600 records sent, 11120.0 records/sec (108.59 MB/sec), 184.7 ms avg latency, 229.0 ms max latency.
54831 records sent, 10966.2 records/sec (107.09 MB/sec), 187.0 ms avg latency, 221.0 ms max latency.
54780 records sent, 10956.0 records/sec (106.99 MB/sec), 186.9 ms avg latency, 243.0 ms max latency.
54235 records sent, 10847.0 records/sec (105.93 MB/sec), 189.0 ms avg latency, 286.0 ms max latency.
55845 records sent, 11169.0 records/sec (109.07 MB/sec), 183.1 ms avg latency, 209.0 ms max latency.
56005 records sent, 11201.0 records/sec (109.38 MB/sec), 183.1 ms avg latency, 201.0 ms max latency.
1000000 records sent, 10475.482134 records/sec (102.30 MB/sec), 194.88 ms avg latency, 704.00 ms max latency, 185 ms 50th, 235 ms 95th, 410 ms 99th, 569 ms 99.9th.
```

我们查看下`hello-kafka` topic的情况：
```
$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic hello-kafka
Topic: hello-kafka	PartitionCount: 1	ReplicationFactor: 1	Configs: segment.bytes=1073741824
	Topic: hello-kafka	Partition: 0	Leader: 0	Replicas: 0	Isr: 0

```

消费下这个topic查看下数据：
```
$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic hello-kafka --group hello-kafka-consumer-group --from-beginning --max-messages 2
```

以上命令，还有各种丰富的参数，留给大家自己去探索了。

5. kcat安装

kafka有自带的客户端，但是个人感觉命令行很繁琐不是很好用。推荐给你个更好用的命令行工具`kcat`。如名，是对kafka的cat查看工具，但其实它不只是查看（consumer），还是一个写入工具（producer）。

通过HomeBrew安装很方便：

```
$ brew install kcat
```

你可以通过`kcat -h`了解下命令行参数。

Low-level 消费kafka topic：
```
$ kcat -C -b localhost:9092 -t hello-kafka
```

High-level 消费kafka topic：
```
$ kcat -b localhost:9092 -G hello-kafka-consumer-group hello-kafka
```

我们将Kafka的LICENSE文件作为消息写入到Kafka中，然后消费出来。
```
$ cat LICENSE|kcat -P -b localhost:9092 -t hello-kafka2

$ kcat -C -b localhost:9092 -t hello-kafka2 -J         
{"topic":"hello-kafka2","partition":0,"offset":0,"tstype":"create","ts":1652945760131,"broker":0,"key":null,"payload":"                                 Apache License"}
{"topic":"hello-kafka2","partition":0,"offset":1,"tstype":"create","ts":1652945760131,"broker":0,"key":null,"payload":"                           Version 2.0, January 2004"}
{"topic":"hello-kafka2","partition":0,"offset":2,"tstype":"create","ts":1652945760131,"broker":0,"key":null,"payload":"                        http://www.apache.org/licenses/"}
......

```

Kafka的内容比较多，参数也很复杂，这里只是一个非常入门的指导。如想了解更详细，可以去官网查看doc。
