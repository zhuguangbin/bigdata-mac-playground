## Spark

1. 下载Spark安装包

我们选择spark的3.1.2版本部署。（实际上hive目前有三个大版本，1.x，2.x，3.x。1.x不建议玩了，3.x比较新，有比较大的改动，2.x是普适性最好的）

```
sudo wget -P /opt https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz
cd /opt
sudo tar zxvf spark-3.1.2-bin-hadoop2.7.tgz
sudo ln -nsf spark-3.1.2-bin-hadoop2.7 spark
```

2. 配置Spark的配置文件

我把我的配置文件放到[conf/spark](../../conf/spark/) 下，供你直接可用

```
sudo mkdir /etc/spark
cd /etc/spark
sudo ln -nsf ~/Code/github/zhuguangbin/bigdata-mac-playground/conf/spark/conf.local conf
```

3. 环境变量

 将以下环境变量加入`~/.zshrc`

```
export SPARK_HOME=/opt/spark
export SPARK_CONF_DIR=/etc/spark/conf
export PATH=$PATH:$SPARK_HOME/bin
```

`source ~/.zshrc`生效

4. Spark 初体验

a. 启动Hadoop

如果Spark运行在YARN上，这步是必须的

```
cd /opt/hadoop
sbin/start-dfs.sh
sbin/start-yarn.sh
```

b. 启动Hive MetaStoreServer

如果运行SparkSQL，这步是必须的，详细的步骤可参考上一节。

```
docker start mysqlserver
cd /opt/hive
bin/hive --service metastore &
```

c. Spark HelloWorld

先本地模式跑一个Pi
```
run-example --master local SparkPi
```

YARN模式跑一下Pi

```
run-example --master yarn SparkPi
```

由于我们默认配置了spark.master为yarn，所以，你可以直接这样运行

```
run-example SparkPi
```

d. SparkSQL 初体验

```
$ spark-sql 
22/05/19 13:57:16 WARN Utils: Your hostname, C02GM22AMD6T resolves to a loopback address: 127.0.0.1; using 192.168.1.40 instead (on interface en0)
22/05/19 13:57:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
22/05/19 13:57:18 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
Spark master: yarn, Application Id: application_1652925379768_0005
spark-sql> show databases;
default
test
Time taken: 1.723 seconds, Fetched 2 row(s)
spark-sql> use test;
Time taken: 0.068 seconds
spark-sql> show tables;
test	hello_hive	false
Time taken: 0.094 seconds, Fetched 1 row(s)
spark-sql> select * from hello_hive limit 10;
1	Bob
2	Alice
3	Lucy
Time taken: 4.935 seconds, Fetched 3 row(s)
spark-sql> create table hello_spark (id INT, name STRING) using orc;
22/05/19 14:16:17 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
Time taken: 0.503 seconds
spark-sql> insert into hello_spark values(1, "Bob"),(2, "Alice"),(3, "Lucy");
Time taken: 3.297 seconds
spark-sql> select * from hello_spark;
2	Alice
3	Lucy
1	Bob
Time taken: 1.004 seconds, Fetched 3 row(s)
spark-sql> desc formatted hello_spark;
id	int	NULL
name	string	NULL
		
# Detailed Table Information		
Database	test	
Table	hello_spark	
Owner	guangzhu	
Created Time	Thu May 19 14:16:18 CST 2022	
Last Access	UNKNOWN	
Created By	Spark 3.1.2	
Type	MANAGED	
Provider	orc	
Location	hdfs://localhost:8020/user/hive/warehouse/test.db/hello_spark	
Serde Library	org.apache.hadoop.hive.ql.io.orc.OrcSerde	
InputFormat	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	
OutputFormat	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	
Time taken: 0.163 seconds, Fetched 16 row(s)
spark-sql> 

```